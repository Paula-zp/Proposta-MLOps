# Proposta de Aprendizado Cont√≠nuo

üë©‚Äçüéì Aluna/Autora: Paula Zanella Piva

üë®‚Äçüè´ Professor: Victor Hayashi

## üìù Detalhamento

O projeto CORA, desenvolvido para o Bank of America, visa a capta√ß√£o de LRRs (Leis, Regulamentos e Resolu√ß√µes) para automatizar o acompanhamento das mudan√ßas regulat√≥rias brasileiras, proporcionando o monitoramento, classifica√ß√£o, exibi√ß√£o e pesquisa das informa√ß√µes.

O projeto √© dividido em 3 etapas:
**1.** Coleta de LRRs com web scraping;
**2.** Tagueamento das LRRs com LLM ( Large Language Model);
**3.** Exibi√ß√£o e pesquisa por √°udio ou texto atrav√©s de PLN.

Atualmente, o sistema enfrenta o desafio de n√£o conseguir se manter atualizado com as novas informa√ß√µes que surgem diariamente. Dessa forma, ele rapidamente se torna obsoleto, pois n√£o consegue se adaptar √† din√¢mica das novas informa√ß√µes em tempo real.

Esse problema est√° relacionado ao conceito de concept drift, que ocorre quando os padr√µes dos dados mudam ao longo do tempo, impactando o desempenho do modelo. No caso da CORA, o concept drift se manifesta quando novas tags s√£o introduzidas ou removidas, alterando a din√¢mica do tagueamento e da pesquisa¬π ¬≤.

Para lidar com esse problema, √© necess√°rio implementar um mecanimo de aprendizado cont√≠nuo que permita a atualiza√ß√£o constante dos modelos, incorporando novos dados e tags¬≥. Estudos como o de Parisi et al. (2019) sobre "Lifelong Learning" refor√ßam a import√¢ncia do aprendizado cont√≠nuo para sistemas que lidam com grandes quantidades de dados din√¢micos, especialmente no campo de PLN, onde os modelos precisam se adaptar constantemente a novos padr√µes‚Å¥.

## Solu√ß√£o Proposta

Para implementar o aprendizado cont√≠nuo no sistema, a arquitetura pode ser adaptada da seguinte maneira:

<div align="center">

<sub>Diagrama</sub>

![Diagrama em blocos da arquitetura proposta](./assets/imagem.png)

</div>

**1. Coleta de LRRs (Web Scraping, valida√ß√£o, encoding)**

Esse m√≥dulo j√° existe e √© respons√°vel por coletar as LRRs de fontes externas diariamente. Ap√≥s a coleta, as LRRs passam por um processo de valida√ß√£o para garantir a integridade e a precis√£o dos dados. Em seguida, os dados s√£o codificados para transformar o texto bruto em uma forma que possa ser utilizada pelos m√≥dulos subsequentes.

O fluxo de dados neste m√≥dulo √©:

Web Scraping: Captura de dados de sites externos.
Valida√ß√£o: Verifica√ß√£o e corre√ß√£o dos dados coletados.
Encoding: Convers√£o dos dados para o formato adequado para processamento.

**2. Banco de dados**
O m√≥dulo de banco de dados ser√° aprimorado para rastrear e armazenar as altera√ß√µes realizadas pelos usu√°rios, como adi√ß√£o e remo√ß√£o de tags. Essas mudan√ßas permitir√£o que o sistema atualize o modelo de tagueamento e o PLN com base no feedback cont√≠nuo dos usu√°rios.

**3. Tagueamento de LRRs (LLM)**

O m√≥dulo de tagueamento utiliza um LLM para ler as LRRs coletadas e gerar automaticamente as tags que melhor representam o conte√∫do dos documentos. O m√≥dulo precisar√° ser atualizado para ter as seguintes funcionalidades:

**A. Gera√ß√£o autom√°tica de tags**: O LLM continuar√° a gerar tags automaticamente, tentando representar os principais temas ou t√≥picos de uma LRR.

**B. Integra√ß√£o com tags manuais**: O sistema ser√° aprimorado para aproveitar as tags j√° criadas pelos usu√°rios, refinando o processo de tagueamento. Isso inclui tanto as tags que os usu√°rios adicionaram quanto as que foram removidas ao longo do tempo. Tags frequentemente aceitas ser√£o sugeridas como op√ß√µes potenciais no processo de novo tagueamento, melhorando a precis√£o do LLM.

**C. Ajuste din√¢mico do modelo**: O m√≥dulo de tagueamento deve ser atualizado regularmente com base nas tags adicionadas ou removidas pelos usu√°rios. Isso permitir√° que o sistema identifique tags que foram mais removidas pelos usu√°rios e ajuste o LLM para n√£o prioriz√°-las nos tagueamento futuros.

**4. Aprendizado Cont√≠nuo**
Esse √© o bloco em que o modelo BERT ser√° atualizado regularmente, com base nas novas tags e altera√ß√µes feitas pelos usu√°rios. Com base nas tags adicionadas ou modificadas, ser√£o geradas novos exemplos de frase, por meio de LLM, para a base de treinamento do modelo. 

O processo de atualiza√ß√£o ocorrer√° de maneira recursiva:

 A. Quando um usu√°rio adiciona uma nova tag a uma LRR, o sistema gera novas frases que representem exemplos de uso dessa tag.

 B. Essas frases s√£o incorporadas ao banco de dados de frases associadas ao modelo BERT, permitindo que ele reconhe√ßa novas inten√ß√µes ou entidades nas consultas.

 C. O modelo BERT ser√° atualizado incrementalmente, evitando o retrabalho completo, mas ajustando-se √†s mudan√ßas para melhorar continuamente a acur√°cia das consultas.

**5. Processamento de Linguagem Natural (PLN): Classifica√ß√£o**
 O m√≥dulo de PLN e classifica√ß√£o √© respons√°vel por analisar e interpretar as LRRs e as consultas dos usu√°rios. Ele utiliza o modelo BERT para identificar as inten√ß√µes e entidades nas consultas e classificar as LRRs de acordo com as tags associadas.

**6. Servi√ßo de Busca**
O m√≥dulo de servi√ßo de busca facilita a recupera√ß√£o de informa√ß√µes do banco de dados com base inten√ß√£o dos usu√°rios. 

**7. Core**
O Core atua como a pe√ßa central que conecta todos os outros m√≥dulos. Ele coordena o fluxo de dados entre os diferentes m√≥dulos, garantindo que as informa√ß√µes sejam processadas corretamente, e gerencia as requisi√ß√µes de servi√ßos.

**8. Speech to Text**
O m√≥dulo Speech to Text converte entradas de √°udio em texto, sendo usado para transformar consultas feitas por voz em um formato que possa ser processado pelo sistema.

## Conclus√£o
A proposta de introduzir aprendizado cont√≠nuo no projeto CORA visa resolver os desafios do concept drift, mantendo o sistema sempre atualizado. Essa solu√ß√£o aprimora a precis√£o do tagueamento e a qualidade das consultas no sistema de PLN, permitindo que o BERT reconhe√ßa novas inten√ß√µes e entidades de forma mais eficiente Embora a implementa√ß√£o exija um esfor√ßo consider√°vel, tanto em termos de desenvolvimento quanto de infraestrutura, o retorno em termos de precis√£o ser√° significativo, garantindo a efici√™ncia da CORA a longo prazo.

## üìö Refer√™ncias
1. ZHAO, H.; LIU, X.; LIU, J. A Survey of Concept Drift Detection Methods. IEEE Xplore, 2020. Dispon√≠vel em: https://ieeexplore.ieee.org/document/9154715. Acesso em: 15 set. 2024.

2. BERTAN, E. O que √© concept drift em machine learning? Medium, 22 mar. 2021. Dispon√≠vel em: https://medium.com/@ericabertan/o-que-√©-concept-drift-em-machine-learning-40ae3c4f0b67. Acesso em: 15 set. 2024.

3. DATA CAMP. What is Continuous Learning? DataCamp, 19 jun. 2023. Dispon√≠vel em: https://www.datacamp.com/pt/blog/what-is-continuous-learning. Acesso em: 16 set. 2024.

4. PARISI, G. I., KEMKER, R., PART, J. L., KANNAN, A., & WERMTER, S. Continual lifelong learning with neural networks: A review. Neural Networks, v. 113, p. 54-71, 2019.